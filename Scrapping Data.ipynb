{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a91c4b",
   "metadata": {},
   "source": [
    "# Scrapping Data\n",
    "\n",
    "#### In many instances, to train your models you may not find a proper dataset or else the dataset will have lot of garbage which you need to handle later. So it is very important to know some basic data scrapping technoques to get data from a website and make your own dataset. Here is easy guide for you to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad456a",
   "metadata": {},
   "source": [
    "### Install libraries properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8728f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884218f",
   "metadata": {},
   "source": [
    "#### In this notebook we will scrape few websites and create a dataset which helpful for creating a CV screening NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8446b44",
   "metadata": {},
   "source": [
    "### Data Scrapping Related to Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa7c4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are gonna use www.jobscan.co to get some data\n",
    "\n",
    "result1 = requests.get(\"https://www.jobscan.co/blog/resume-words/\")\n",
    "soup1 = BeautifulSoup(result1.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c076deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it is a table we need to look in table and its atributes\n",
    "\n",
    "xxs = soup1.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c30db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<td>.NET</td>, <td>Zealous</td>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the end and the start\n",
    "\n",
    "xxs[0],xxs[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "200660b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of them to a list\n",
    "\n",
    "scrap_skills = list(map(lambda x:x.text,xxs[0:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a80705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.NET',\n",
       " 'fashion',\n",
       " 'process improvement',\n",
       " 'account management',\n",
       " 'FDA',\n",
       " 'process improvements',\n",
       " 'accounting',\n",
       " 'field sales',\n",
       " 'procurement',\n",
       " 'accounts payable']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_skills[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917597b",
   "metadata": {},
   "source": [
    "### Data Scrapping realted to Job Titles names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b5952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are gonna use www.joblist.co to get some data\n",
    "\n",
    "req = requests.get(\"https://www.joblist.com/b/all-jobs\")\n",
    "soup = BeautifulSoup(req.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03431a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the html lines we are interested in\n",
    "\n",
    "filter_data = soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c56f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><a href=\"/\">Home</a></li>\n",
      "<li><a href=\"/about\">About</a></li>\n",
      "<li><a href=\"/career-advice\">Blog</a></li>\n",
      "<li><a href=\"/faq\">FAQ</a></li>\n",
      "<li><a href=\"/contact-us\">Contact</a></li>\n",
      "<li><a href=\"/post-a-job\">Post a Job</a></li>\n",
      "<li><a href=\"/search\">Find Jobs</a></li>\n",
      "<li><a href=\"/login\">Log In</a></li>\n",
      "<li><a href=\"/signup\">Sign Up</a></li>\n",
      "<li data-cy=\"browse-list-link\"><a href=\"/b/Truck-Driver-jobs\">Truck Driver</a></li>\n",
      "<li data-cy=\"browse-list-link\"><a href=\"/b/Nurse-jobs\">Nurse</a></li>\n",
      "<li data-cy=\"browse-list-link\"><a href=\"/b/Sales-jobs\">Sales</a></li>\n"
     ]
    }
   ],
   "source": [
    "#find the start of the interested lines\n",
    "\n",
    "for i in range(0,12): print(filter_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d0eef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da9b7376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li data-cy=\"browse-list-link\"><a href=\"/b/Timekeeper-jobs\">Timekeeper</a></li>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the end of the interested lines\n",
    "\n",
    "filter_data[4762]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e865dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timekeeper'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you need the text part \n",
    "filter_data[4762].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e37dc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of them to a list\n",
    "\n",
    "scrap_job = list(map(lambda x:x.text,filter_data[9:4762]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "832c7b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Truck Driver',\n",
       " 'Nurse',\n",
       " 'Sales',\n",
       " 'Company Driver',\n",
       " 'Registered Nurse',\n",
       " 'Otr Driver',\n",
       " 'Caregiver',\n",
       " 'Delivery Driver',\n",
       " 'Customer Service',\n",
       " 'Analyst']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_job[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2339125",
   "metadata": {},
   "source": [
    "#### Lets try something a little harder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d7b7c",
   "metadata": {},
   "source": [
    "### Data Scrapping Related to Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec9016f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are gonna use www.keycdn.com to get some data\n",
    "\n",
    "result2 = requests.get(\"https://www.keycdn.com/blog/web-development-tools\")\n",
    "soup2 = BeautifulSoup(result2.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c41f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we need to narrow down a little more, so we use its attributes\n",
    "\n",
    "xxd = soup2.find_all('a',attrs={'rel':'nofollow noopener'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e99ca19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<a href=\"http://backbonejs.org\" rel=\"nofollow noopener\" target=\"_blank\">BackBoneJS</a>,\n",
       " <a href=\"https://gtmetrix.com\" rel=\"nofollow noopener\" target=\"_blank\">GTmetrix</a>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxd[4],xxd[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3147374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of them to a list\n",
    "\n",
    "scrap_skills2 = list(map(lambda x:x.text,xxd[4:126]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "980f4919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BackBoneJS',\n",
       " 'D3.js',\n",
       " 'React',\n",
       " 'jQuery UI',\n",
       " 'jQuery Mobile',\n",
       " 'Underscore.js',\n",
       " 'Moment.js',\n",
       " 'Lodash',\n",
       " 'Vue.js',\n",
       " 'Bootstrap']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_skills2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13bbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
